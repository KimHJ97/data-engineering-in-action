# ElasticSearch란

## ElasticSearch

 - 텍스트, 숫자, Geospatial, 정형 및 비정형 데이터 등의 데이터에 대한 검색, 분석이 가능한 검색 엔진 또는 Information Retrieval 라이브러리
 - Apache Lucene을 기반으로 구축
 - REST API, 분산 처리, 속도, 확장성의 특징을 갖고 있음
 - Inverted Index: 역색인을 통해 빠르게 검색이 가능하다. 검색을 원하는 해당 단어가 포함된 모든 문서의 위치를 알 수 있다.
 - 확장성과 가용성: 분산 구성이 가능한 구조. 샤드를 통해 데이터를 분산해서 빠르게 처리 가능

### ElasticSearch 단점

 - 실시간은 아님(Near Real Time): 인덱싱된 데이터는 1초 뒤에 검색이 가능함
 - 트랜잭션, 롤백 불가: 분산 시스템으로 구성되어 있음. 리소스 소모가 큰 롤백이나 트랜잭션은 지원하지 않아 데이터 손실의 위험이 있음
 - 데이터 업데이트 불가: 업데이트는 기존 문서를 삭제하고 변경 내용으로 새 문서를 생성하는 reindexing 방식으로 비용이 큰 편

## ELK 스택

 - 데이터 수집: Logstash(Beats)
 - 데이터 처리: ElasticSearch
 - 데이터 분석: Kibana

### Logstash

 - 다양한 소스에서 데이터를 수집하여 변환한 후 자주 사용하는 저장소로 전달하는 기능
 - 플러그인 기반: 파이프라인을 구성하는 각 요소들은 전부 플러그인 형태. 기본 플러그인 외에도 수 많은 커뮤니티 플러그인이 존재
 - 모든 형태의 데이터 처리: 플러그인들의 조합으로 다양한 형태의 데이터를 입력받아 가공한 다음에 저장이 가능
 - 성능: 자체적 내장 메모리, 파일 기반의 큐를 통해 안정성이 높고 처리 속도가 빠름. 벌크 인덱싱 및 파이프라인 배치 크기 조정을 통한 병목 현상을 방지,  성능 최적화 기능
 - 안정성: 엘라스틱 서치의 장애 상황에 대응하기 위한 재시도 로직이나 오류가 발생한 도큐먼트를 따로 보관하는 Dead-Letter-Queue를 내장하고 있음
 - Input
    - 외부에서 데이터를 받아오는 영역
    - file: 경로 지정한 파일을 읽는 방식
    - syslog: 리눅스 시스템에서 시스템 로그를 읽음
    - redis: redis에서 데이터를 읽음
    - beats: Beats에서 데이터를 읽음
 - Filter(Optional)
    - 입력받은 데이터를 가공. 조건에 대한 가공
    - grok: grok 패턴(정규식 비슷)을 사용해 메시지를 구조화된 형태로 분석. 대부분의 텍스트 포맷을 처리할 수 있음
    - mutate: 필드 이름 변경, 삭제, 추가
    - date: 문자열을 지정한 패턴의 날짜형으로 변경
 - Output
    - 입력과 필터를 거친 데이터를 Target 대상으로 보내는 단계
    - elasticsearch: Elasticsearch에 인덱싱을 수행
    - file: 파일에 저장
    - Kafka: Kafka Topic에 데이터 전송

<div align="center">
    <img src="./images/basic_logstash_pipeline.png">
</div>
<br/>

### Kibana

 - ElasticSearch에 있는 데이터를 시각화하고 Elastic Stack을 탐색
 - 저장된 데이터 분석, 시각화하는 데 사용
 - 데이터의 패턴과 동향을 파악하고 인사이트를 얻음
 - Kibana 대시보드는 여러 그래프와 차트를 한 눈에 볼 수 있는 화면을 제공. 사용자는 데이터의 상태와 성능을 실시간으로 모니터링
 - Discover: 데이터 확인
 - Visualize: 데이터 시각화
 - Dashboard: 시각화 차트 모아보기
 - Setting: 인덱스 등록, 설정
